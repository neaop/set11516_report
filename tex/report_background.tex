\section{Background} \label{sec_background}
This section of the report provides a review and analysis of existing reports,
technical papers, and studies with the aim of providing context and evidence
of feasibility for this project.

The majority of the literature presented was aggregated prior to planning and
implementation of the simulated/real-world SLAM solution documented in this
report, and thus provided the inspiration and domain specific knowledge
required to carry out the project.


\subsection{SLAM}
As previously stated, SLAM is computational problem consisting of the
completion of the tasks robotic navigation and robotic mapping in parallel.
SLAM solutions are often highly tailored to a particular technology,
environment, or accuracy - and as such are utilised as approximation
techniques, rather than a perfect resolution.

Countless systems employing SLAM techniques have been researched and developed
for multiple domains, including but limited to; self-driving cars, planetary
rovers, domestic robots, and unmanned aerial and submersible vehicles.

\subsubsection{Origins}
The preliminary investigation into SLAM and SLAM solutions was conducted by
R.C. Smith and P. Cheeseman in 1986 with their exploration of the concept of
Spatial Uncertainty and manners in which it could be estimated
\cite{Smith1986,Smith1988}.
Within these works it was reasoned that it would be advantageous for robots to
be able to estimate their current location relative to objects or obstacles
within an environment.

An example provided within the seminal study describes being
able to calculate the probability of a robot being able to pass through a
door frame, given the robots uncertain location, the uncertain location of the
door, and the likelihood that the robot's sensors can detect said door
\cite{Smith1986}. 
The paper goes on to describe how a robot's estimated location grows in
uncertainty as moves from its initial location, and that by utilising the
robot's sensors to make relative measurements between objects or features in the
environment, probabilistic information can be gained about the global
environment - and thus the robots location.
The paper proposed a potential estimation method that could be used to aid
in the spatial estimation of a robot in an environment, and the simulations
conducted suggested it was possible to attain close to 90\% accuracy utilising
Monte Carlo and Gaussian techniques.

Smith and Cheeseman's later work with M. Self focused on the concept of
representing spatial information in a `Spatial Map', and the probabilistic
manners in which the map could be constructed, read, and revised as new
information of the environment was gained \cite{Smith1988}.
The motivation behind \citeauthor{Smith1988}'s paper was to aid mobile robots
navigate an environment, without the need of extremely precise and expensive
sensors, or known fixed calibration locations in the area.
The study discusses how the use of inexpensive, overlapping sensors could be
used in the stead of more advanced sensors, provided that the uncertainty of
each sensors measurements were combined when said measurements were utilised
for navigation calculations.
The paper goes on to make the argument that when utilising inexpensive mobile
robots that overlapping low quality sensors may be one of the only ways to
implement a navigation solution of sufficient operational accuracy.
A simple description of the proposed techniques is described in the paper, and
bears many resemblances to modern SLAM solutions:

\begin{itemize}
    \item The robot senses object \#1.
    \item The robot moves. 
    \item The robot senses an object (object \#2) which it determines cannot be
    object \#1.
    \item Trying again, the robot succeeds in sensing object \#1, thus helping
    to localize itself, object \#1, and object \#2.
\end{itemize}

\citeauthor*{Smith1988}'s work into the concept of Spatial Estimation
provided much of the early footwork required to advance SLAM and SLAM
solutions, and while the two papers discussed previously were mostly
theoretical or general, they paved the way for more concrete implementations
of SLAM and autonomous navigation solutions as we currently know them.

One of the first successful practical applications of a SLAM solution outside of
research experiments was in 2005, when Stanford University claimed first
place in the DARPA Grand Challenge.
The DARPA Grand Challenge was a competition funded by the American Defence
Advanced Research Projects Agency, where competitions were challenged to
develop autonomous ground vehicles that could navigate a lengthy, off-road
course in a given time limit. 
STANLEY (Stanford Universities vehicle), utilised a stock Volkswagen
Touareg R5, a number of sensors, and numerous SLAM techniques to navigate the
desert course.

In 2007 the DARPA Grand Challenge took place in an urban environment, forcing
competing vehicles to comply with traffic regulations and other road vehicles.
Stanford's entry to the 2007 completion, JUNIOR utilised much of the same
technologies and techniques as its predecessor STANLEY, and was able to achieve
second place in the competition.

Sebastian Thrun headed the Stanford University team in each of the DARPA Grand
Challenges, and his entries utilisation of SLAM techniques to aid in
navigation has been credited as bringing SLAM into public focus, promoting
further development and utilisation of SLAM solutions in navigation based
applications. \editnote{REF here!}

\subsubsection{SLAM Algorithms}
As a concept, SLAM has existed for a substantial period, and as such multiple
potential solutions to the problem have been developed.
As previously stated, suitability of SLAM algorithm depends heavily on the,
environment to be navigated, the available hardware, and the type of map to
produced - meaning that no single SLAM solution can be considered optimal for
all permutations of equipment and environmental parameters.
New SLAM algorithms and solutions are still being theorised and tested, as
navigation problems remain a key interest of research - both in industry and
academia.

The SLAM problem can be represented simply in a formulaic manner:

\[ P(m_t,x_t|o_{1:t}) \]

Considering a set of sensors observations \(o_t \), over a number of time
steps \(t\), the goal of a SLAM solution is to probabilistically calculate an
estimated map of an environment \(m_t\), and the location of an agent in said
map \(x_t\).

While simple to describe, the SLAM problem requires significantly more
involved techniques to provide a satisfactory solution.

Statistical approaches to SLAM problems are common, specifically {\bf Monte
Carlo} methods - an approach suggested by \citeauthor{Smith1986} in their
preliminary exploration of the field.
Monte Carlo methods are algorithms that operate by repeatedly collecting
random samples in order to generate a probabilistic estimate.
Two of the more common approaches to SLAM problems that utilise Monte Carlo
techniques are {\bf Kalman Filters} and {\bf Particle Filters}.

`SLAM for Dummies' is a tutorial paper that describes the process of
implementing an Extended Kalman Filter based solution to the SLAM problem
\cite{Riisgaard2004}.  
The title of the paper belies the through and involved process the authors
took to fully document the hardware, tools, and techniques utilised -
providing a fully fleshed and informative guide to implementation of a fully
functional SLAM solution.
\citeauthor{Riisgaard2004}'s paper was paramount to the inception and
development of this project, providing much needed context and explanation to
much of the domain specific terminology utilised by other studies in the
domain.

\subsubsection{Inexpensive Robots}
The early research into SLAM solutions, and mobile robot navigation in general
had a strong focus on producing suitable methods that did not require
extravagant, expensive, or niche hardware to function.
In much the same vein as the seminal studies into Spatial Estimation, this
project aims to produce a SLAM solution utilising an inexpensive mobile
robot platform.
The studies presented thusly provide insight and evidence into the
construction of navigation solutions using more affordable technologies.

The SLAM problem requires robots to be able detect or observe their
surroundings to accurately estimate their location or plat points to a map.
An issue with many inexpensive real-world sensors is that lack detection
fidelity past a certain range.
Typical SLAM solutions utilise sensors mounted to a robot perpendicular to
floor, i.e. detecting objects horizontal to the robot.
In order to counter affordable sensor's limited range of effectiveness, several
studies have opted to instead monitor and observe differences in the surface
that a robot moves across to estimate the robot's location.

A 2016 study proved that it was indeed possible for a robot to be able to
localise itself utilising infrared sensors to detect the grey-scale colour of
the ground beneath the robot and approximate dead-reckoning \cite{Wang2016}.
The system described in the paper utilises a two forms of {\bf Monte Carlo}
method to aid in determining the robot's location.
The paper described how robotic agents moving over a well defined landscape -
in the case of the study; A2 size patterns were used, could utilise
their low-performance sensors to detect the colour beneath themselves and
calculate their approximate position.
While the premise and results of the paper were promising, the robtic agents
required the robotic agents to have prior knowledge the area in which they
were localising - providing a solution for only half of the SLAM problem.
While not a complete solution to SLAM, the paper does show that at least
localisation is possible using only low-quality infrared sensors.

Due to their low cost, relative ease of use, and low power consumption,
infrared sensors have become a common replacement to more costly - but
effective, laser scanners.
Numerous investigations have been conducted to determine whether infrared
sensor alone can provide enough detailed data to allow successful SLAM
navigation.

A 2008 study experimented with a commercial vacuum cleaner robot and 7 infrared
sensors to determine whether it was possible to construct a successful SLAM
solution using the `noisy' data provided by the sensors \cite{Choi2008}.
The sensors utilised in the investigation had an effective range of 20-150cm -
outwith these ranges the sensors were unreliable or excessively noisy to
correctly observe the environment.
The 7 infrared sensors were equally spaced around the forward facing half of
the circular robot - and the robot's built in odometry provided an estimated
location for the robot once it had moved from it's random initial starting
location.
In terms of the implemented algorithm, a {\bf Line Feature} SLAM solution was
developed - line based SLAM solution limit the mobile robot's movements to
consist of straight, orthogonal, and parallel lines.
While the forced geometric movements of the robots in the study limited the
exploration potential of the system, it provided ample navigation of a typical
room layout - ideal for domestic platforms, such as the one utilised in the
study.
An {\bf Extended Kalman Filter} model was utilised to calculate feature
distance estimations and measurement uncertainties.
Tests indicated that the  robot was able to successfully navigate a 4x4 meter
room containing free standing and wall contact obstacles.
Considering the robot's effective sensor range only reached ~37\% of the rooms
total size, the robots ability to successfully, navigate and map the room and
its contents indicates that infrared sensors and odometery can be utilised to
implement SLAM solutions - at least for simple environments.

Preliminary investigation into the use of inexpensive robotic platforms or
sensing hardware indicates that infrared sensors and some form of estimated
localisation (dead-reckoning, or isometry) can lead to successful SLAM solution
implementations.


\subsection{Routing Problems}

\subsection{Robotic Simulators}



\pagebreak

\editnote{REWORK!}
\subsection{Autonomous Robots and Vehicles}
SLAM, and autonomous navigation in general, has long been concept of interest
in a range of domains.
Academic, corporate, and government originations all have vested interest in
the advancement of self-navigating vehicles and robots, and a wide range of
such devices have already been developed and used to great affect.

One of the more common uses of autonomous navigation is in the exploration of
environments or areas that inhospitable to human life.

\subsubsection{Automotive}
Automotive automation is a key domain in which research has been focused in
recent years.
A wide range of organisation have all shown a great deal interest in the testing
and production of autonomous vehicles - well established car production companies
such as Mercedes Benz and BMW, technology companies like Google, and even
relatively new organisations like Tesla, Inc. and Uber Technologies Inc., have
all invested a significant amount of time and resources in the pursuit of
development, testing, and production of safe and reliable autonomous cars.

The concept of unmanned vehicles is not a new concept - the testing of radio
controlled cars dates back to mid 1920's, but recent research has had a much
stronger focus on the improvement of vehicles hazard detection and navigation
capabilities.

Due to the age of the concept of autonomous vehicles, a number of discrepancies
have arisen in regards to the correct terminology that should be utilised
within the field.
The name of the field has even come under security - arguments have been made
that the name `Automated Vehicles' would be more appropriate, as the term
autonomous implies the vehicle is entirely self governing, whereas in
reality most implementations of self-driving vehicles rely on some form of
external factors; magnetic strips, road markings, communications from other
vehicles, etc..
In order to aid with standardisation of terminology within the field, an
automotive standards body, SAE International, defined a system in 2014
(J3016), allowing the classification of autonomous or automated vehicles
depending on the required user input or interaction with the vehicle.

J3016 categorises vehicles into one of 6 levels - with level 0 having no form
of autonomy, and level 5 being operating with full automation.
Informal definitions for each level are provides as follows:

\begin{itemize}
\item Level 0 - system may issue warnings, but no sustained control.
\item Level 1 - `hands on' - driver and system share vehicle control.
\item Level 2 - `hands off' - system controls vehicle, but driver must monitor
                and be ready to intervene.
\item Level 3 - `eyes off' - driver is not required to monitor operation of
                system, but may be required to perform some specific driving tasks.
\item Level 4 - `mind off' - system can control vehicle entirely, but only
                within specific locations or circumstances.
\item Level 5 - `steering wheel optional' - no human intervention required.
\end{itemize}

The complete J3016 Autonomy Level definitions are visible in Appendix \ref{app-sae}. 

While SAE level 4 and 5 systems are still under development, Audi claims that
their 2018 A8 Luxury Sedan is capable of SAE level 3 automation - The built
in `AI traffic jam pilot' is able to control the vehicle at speeds up to 60
kilometres per hour, and can perform actions such as steering, acceleration
and deceleration, steering, and starting from a dead-stop.




\subsubsection{Military}
One of the proposed domains where the use of autonomous agents or vehicles
could be advantageous is within military or combat scenarists - i.e. events
where rival or rouge agents may be attempting to delay, destroy, hijack, or
sabotage operations within an area.

While the use of autonomous, `intelligent' agents within combat situations
has number of ethical and morality concerns, the use of robotics by military
organisations is already underway.
Unmanned, but human controlled robotic platforms are heavily utilised to aid
with scouting or the disposal of hazardous objects - such as mines.
Further research has also been conducted into the feasibility of unmanned
vehicles aiding in the transport of of aid or materials through hazardous
fronts, and for use as evacuation or ambulance-like transport vehicles - to
help wounded personnel or aid in extraction scenarios.

There are a number of benefits to introducing autonomous agents within a military context.
One benefit is the reduced personnel, or personnel training, required to
operate specialist equipment.  
Lockheed Martin has been researching and developing a semi-autonomous
personnel carrier vehicle, utilised to safely transport human passengers to
and from dangerous areas.
The Autonomous Mobility Applique System (AMAS) can operate in a
`follow-the-leader` style fashion, where a convey of autonomous vehicles can
safely an accurately follow a designated, human operated, control vehicle.
Current test have shown that up to 7 AMAS vehicles can autonomous follow a
control vehicle, allowing the 14 navigation and driving personnel previously
required to perform other tasks during transportation.
Additionally, the AMASS can aid human driver by automatically detecting and
avoiding potential hazards that a human driver may miss - allowing personnel to operate
the vehicle at a reduced risk to themselves, passengers, and other vehicles.
Lokheed Martin also developed a smaller scale version of the AMAS, the Squad Mission
Support System (SMSS).

The SMSS utilises a similar `follow-the-leader' system to the larger AMAS, but
is designed to follow personnel on foot, carrying any tools or supplies that
might be required in the field.
The SMSS has already been deployed and used in multiple scenarios across the
globe, and has proven that autonomous mobile equipment can be a dependable
asset to combat personnel.

Lokheed Martin's motivation behind both the AMAS and SMSS designs was to
``improve the safety for the soldiers.''.
By producing equipment and vehicles that do not require human operation, the
number of personnel required to actively participate can be severely reduced,
removing the number of people required to enter hostile locations.
Additionally, the autonomous aid provided can servery reduce the physical and
mental load military personnel must endure in active duty.
It is crucial to note that the technologies outlined are not exclusive to
the military sector, in fact Lokheed has previously stated there goal of
reworking there autonomous platforms to be suitable for use in the consumer and
public domains, such as medical and search and rescue.

\noindent\rule{\textwidth}{1pt}
