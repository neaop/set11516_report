\section{Background} \label{sec_background}
This section of the report provides a review and analysis of existing reports,
technical papers, and studies with the aim of providing context and evidence
of feasibility for this project.

The majority of the literature presented was aggregated prior to planning and
implementation of the simulated/real-world SLAM solution documented in this
report, and thus provided the inspiration and domain specific knowledge
required to carry out the project.


\subsection{SLAM} \label{sec_slam}
As previously stated, SLAM is computational problem consisting of the
completion of the tasks robotic navigation and robotic mapping in parallel.
SLAM solutions are often highly tailored to a particular technology,
environment, or accuracy - and as such are utilised as approximation
techniques, rather than a perfect resolution.

Countless systems employing SLAM techniques have been researched and developed
for multiple domains, including but limited to; self-driving cars, planetary
rovers, domestic robots, and unmanned aerial and submersible vehicles.

As a concept, SLAM has existed for a substantial period, and as such multiple
potential solutions to the problem have been developed.
As previously stated, suitability of SLAM algorithm depends heavily on the,
environment to be navigated, the available hardware, and the type of map to
produced - meaning that no single SLAM solution can be considered optimal for
all permutations of equipment and environmental parameters.
New SLAM algorithms and solutions are still being theorised and tested, as
navigation problems remain a key interest of research - both in industry and
academia.

The SLAM problem can be represented simply in a formulaic manner:

\[ P(m_t,x_t|o_{1:t}) \]

Considering a set of sensors observations \(o_t \), over a number of time
steps \(t\), the goal of a SLAM solution is to probabilistically calculate an
estimated map of an environment \(m_t\), and the location of an agent in said
map \(x_t\).

While simple to describe, the SLAM problem requires significantly more
involved techniques to provide a satisfactory solution.

\subsubsection{SLAM Algorithms}
While a wide range of potential solutions to the problem of SLAM exist, most
solutions can be broken down into three distinct steps \cite{Sola2013}. 
A concise definition of each step is provided:

\begin{itemize}
\item The robot moves, reaching a new point of view of the scene. 
Due to unavoidable noise and errors, this motion increases the uncertainty on
the robotâ€™s localization.
An automated solution requires a mathematical model for this motion. We call
this the motion model.

\item The robot discovers interesting features in the environment, which need
to be incorporated to the map. 
We call these features landmarks. 
Because of errors in the exteroceptors sensors, the location of these
landmarks will be uncertain.
Moreover, as the robot location is already uncertain, these two uncertainties
need to be properly composed. 
An automated solution requires a mathematical model to determine the position
of the landmarks in the scene from the data obtained by the sensors. 
We call this the inverse observation model.

\item The robot observes landmarks that had been previously mapped, and uses
them to correct both its self-localization and the localization of all
landmarks in space.
In this case, therefore, both localization and landmarks uncertainties
decrease.  
An automated solution requires a mathematical model to predict the
values of the measurement from the predicted landmark location and the robot
localization. 
We call this the direct observation model.
\end{itemize}

The combination of the three previously defined models and `estimation engine'
\cite{Sola2013} allow an agent to approximate its own location and the features
of the surrounding  area.
There exist multiple implementations of estimation engines, one of the most
commonly utilised systems is the Extended Kalman Filters (EKF) \cite{4378854}
- often consider the most accurate forms of non-linear estimation
  \cite{1271397}, and heavily utilised in systems like GPS and guidance
  systems.
An alternative estimation engine to EKF is the Particle Filter, a more
computational expensive Monte Carlo implementation mainly utilised in
filtering problems \cite{Bugallo2007}.

\subsubsection{Origins}
The preliminary investigation into SLAM and SLAM solutions was conducted by
R.C. Smith and P. Cheeseman in 1986 with their exploration of the concept of
Spatial Uncertainty and manners in which it could be estimated
\cite{Smith1986,Smith1988}.
Within these works it was reasoned that it would be advantageous for robots to
be able to estimate their current location relative to objects or obstacles
within an environment.

An example provided within the seminal study describes being
able to calculate the probability of a robot being able to pass through a
door frame, given the robots uncertain location, the uncertain location of the
door, and the likelihood that the robot's sensors can detect said door
\cite{Smith1986}. 
The paper goes on to describe how a robot's estimated location grows in
uncertainty as moves from its initial location, and that by utilising the
robot's sensors to make relative measurements between objects or features in the
environment, probabilistic information can be gained about the global
environment - and thus the robots location.
The paper proposed a potential estimation method that could be used to aid
in the spatial estimation of a robot in an environment, and the simulations
conducted suggested it was possible to attain close to 90\% accuracy utilising
Monte Carlo and Gaussian techniques.

Smith and Cheeseman's later work with M. Self focused on the concept of
representing spatial information in a `Spatial Map', and the probabilistic
manners in which the map could be constructed, read, and revised as new
information of the environment was gained \cite{Smith1988}.
The motivation behind the study was to aid mobile robots navigate an
environment, without the need for extremely precise and expensive sensors, or
known fixed calibration locations in the area.
The study discusses how the use of inexpensive, overlapping sensors could be
used in the stead of more advanced sensors, provided that the uncertainty of
each sensors measurements were combined when said measurements were utilised
for navigation calculations.
The paper goes on to make the argument that when utilising inexpensive mobile
robots that overlapping low quality sensors may be one of the only ways to
implement a navigation solution of sufficient operational accuracy.
A simple description of the proposed techniques is described in the paper, and
bears many resemblances to the modern SLAM solution steps:

\begin{itemize}
    \item The robot senses object \#1.
    \item The robot moves. 
    \item The robot senses an object (object \#2) which it determines cannot be
    object \#1.
    \item Trying again, the robot succeeds in sensing object \#1, thus helping
    to localize itself, object \#1, and object \#2.
\end{itemize}

\citeauthor*{Smith1988}'s work into the concept of Spatial Estimation
provided much of the early footwork required to advance SLAM and SLAM
solutions, and while the two papers discussed previously were mostly
theoretical or general, they paved the way for more concrete implementations
of SLAM and autonomous navigation solutions as we currently know them.

One of the first successful practical applications of a SLAM solution outside of
research experiments was in 2005, when Stanford University claimed first
place in the DARPA Grand Challenge \cite{dahlkamp2006self}.
The DARPA Grand Challenge was a competition funded by the American Defence
Advanced Research Projects Agency, where competitors were challenged to
develop autonomous ground vehicles that could navigate a lengthy, off-road
course in a given time limit \cite{buehler20072005}. 
STANLEY (Stanford Universities vehicle), utilised a stock Volkswagen
Touareg R5, a number of sensors, and numerous SLAM techniques to navigate the
desert course \cite{thrun2006stanley}.

In 2007 the DARPA Grand Challenge took place in an urban environment, forcing
competing vehicles to comply with traffic regulations and other road vehicles.
Stanford's entry to the 2007 completion, JUNIOR utilised much of the same
technologies and techniques as its predecessor STANLEY, and was able to achieve
second place in the competition \cite{montemerlo2008junior}.

Sebastian Thrun \cite{sebastian} headed the Stanford University team in each
of the DARPA Grand Challenges, and his entries utilisation of SLAM techniques
to aid in navigation \cite{Thrun2006} has been credited as bringing SLAM into
public focus, promoting further development and utilisation of SLAM solutions
in

\editnote{in what?}

\subsubsection{SLAM Implementations}
SLAM algorithms have been proven to be effective solutions to the problem
autonomous navigation, and have been utilised in a wide array of applications
and systems.

Recent interest in the concept of autonomous or self-driving cars has
re-establish SLAM as a `hot-topic' in terms of research.

Commercial, autonomous, self-driving cars are current focus of media and
corporate interest.
A wide range of organisation have all shown a great deal interest in the testing
and production of autonomous vehicles - well established car production
companies such as Mercedes Benz and BMW, technology companies like Google, and
even relatively new organisations like Tesla, Inc. and Uber Technologies Inc.,
have all invested a significant amount of time and resources in the pursuit of
development, testing, and production of safe and reliable autonomous cars
\cite{waymo,tesla,uber,mercedes,bmw_2018}.
While automobile technology may have advanced since the premier of STANLEY,
SLAM solutions are still heavily utilised within the industry, as are other
navigation and computer vision techniques.

While SLAM is a common technology utilised within the autonomous vehicle
sector, the wide range of implementations and terminology has lead to confusion
within the sector.
In order to aid with standardisation of terminology within the field, an
automotive standards body, SAE International, defined a system in 2014
(J3016), allowing the classification of autonomous or automated vehicles
depending on the required user input or interaction with the vehicle
\cite{standard2014j3016}.

J3016 categorises vehicles into one of 6 levels - with level 0 having no form
of autonomy, and level 5 being operating with full automation.
Informal definitions for each level are provides as follows:

\begin{itemize}
\item Level 0 - system may issue warnings, but no sustained control.
\item Level 1 - `hands on' - driver and system share vehicle control.
\item Level 2 - `hands off' - system controls vehicle, but driver must monitor
                and be ready to intervene.
\item Level 3 - `eyes off' - driver is not required to monitor operation of
                system, but may be required to perform some specific driving tasks.
\item Level 4 - `mind off' - system can control vehicle entirely, but only
                within specific locations or circumstances.
\item Level 5 - `steering wheel optional' - no human intervention required.
\end{itemize}

The complete J3016 Autonomy Level definitions are visible in Appendix
\ref{app-sae}. 

SLAM implementations can also be found in more readily available products,
such as robotic vacuum cleaners, and other autonomous  domestic products
\cite{forlizzi2006service}.
The sheer range of domains and products that utilise SLAM techniques
solidifies its position as one of the superior methods of solving the issue of
autonomous mapping and navigation.



\subsection{Inexpensive Robots}
The early research into SLAM solutions, and mobile robot navigation in general
had a strong focus on producing suitable methods that did not require
extravagant, expensive, or niche hardware to function.
In much the same vein as the seminal studies into Spatial Estimation, this
project aims to produce a SLAM solution utilising an inexpensive mobile
robot platform.
The studies presented thusly provide insight and evidence into the
construction of navigation solutions using more affordable technologies.

The SLAM problem requires robots to be able detect or observe their
surroundings to accurately estimate their location or plot points on a map.
An issue with many inexpensive real-world sensors is that lack detection
fidelity past a certain range.
Typical SLAM solutions utilise sensors mounted to a robot perpendicular to
floor, i.e. detecting objects horizontal to the robot.
In order to counter affordable sensor's limited range of effectiveness, several
studies have opted to instead monitor and observe differences in the surface
that a robot moves across to estimate the robot's location.

A 2016 study proved that it was indeed possible for a robot to be able to
localise itself utilising infrared sensors to detect the grey-scale colour of
the ground beneath the robot and approximate dead-reckoning \cite{Wang2016}.
The system described in the paper utilises a two forms of  Monte Carlo
method to aid in determining the robot's location.
The paper described how robotic agents moving over a well defined landscape -
in the case of the study; A2 size patterns were used, could utilise
their low-performance sensors to detect the colour beneath themselves and
calculate their approximate position.
While the premise and results of the paper were promising, the robotic agents
required the robotic agents to have prior knowledge the area in which they
were localising - providing a solution for only half of the SLAM problem.
While not a complete solution to SLAM, the paper does show that at least
localisation is possible using only low-quality infrared sensors.

Due to their low cost, relative ease of use, and low power consumption,
infrared sensors have become a common replacement to more costly - but
effective, laser scanners.
Numerous investigations have been conducted to determine whether infrared
sensor alone can provide enough detailed data to allow successful SLAM
navigation.

A 2008 study experimented with a commercial vacuum cleaner robot and 7 infrared
sensors to determine whether it was possible to construct a successful SLAM
solution using the `noisy' data provided by the sensors \cite{Choi2008}.
The sensors utilised in the investigation had an effective range of 20-150cm -
outwith these ranges the sensors were unreliable or excessively noisy to
correctly observe the environment.
The 7 infrared sensors were equally spaced around the forward facing half of
the circular robot - and the robot's built in odometry provided an estimated
location for the robot once it had moved from it's random initial starting
location.
In terms of the implemented algorithm, a  Line Feature SLAM solution was
developed - line based SLAM solutions limit the mobile robot's movements to
consist of straight, orthogonal, and parallel lines.
While the forced geometric movements of the robots in the study limited the
exploration potential of the system, it provided ample navigation of a typical
room layout - ideal for domestic platforms, such as the one utilised in the
study.
An EKF model was utilised to calculate feature distance estimations and
measurement uncertainties.
Tests indicated that the  robot was able to successfully navigate a 4x4 meter
room containing free standing and wall contact obstacles.
Considering the robot's effective sensor range only reached ~37\% of the rooms
total size, the robots ability to successfully, navigate and map the room and
its contents indicates that infrared sensors and odometery can be utilised to
implement SLAM solutions - at least for simple environments.

Preliminary investigation into the use of inexpensive robotic platforms or
sensing hardware indicates that infrared sensors and some form of estimated
localisation (dead-reckoning, or isometry) can lead to successful SLAM solution
implementations.


\subsection{Robotic Simulation} \label{sec_sim}
Robotic simulators, and simulators in general, provide the ability to design
and test a  systems behaviour, outwit the system itself. 
Simulators have long been employed, as the resource and time cost of a project
can be significantly reduced - particularly in projects that would otherwise
utilise expensive or niche hardware requirements.

While a simulator's resource saving advantages are obvious, there exists other
benefits to employing the use of a simulation software - particularly in
robotic themed projects.
One such advantage is a simulators potential to generate sample data that can
be used in the training or evaluation of genetic or evolutionary robotic
systems.
A number of studies have concluded that the use of robotic simulators can
aid in the improvement of robots that employ non-deterministic behaviour
\cite{7139550,7139557}.
This claim was found to be epically true in studies concerning swarm robotics
- a domain that focuses on the use of multiple agents working together to solve
a single problem \cite{Wischmann864,R2016,Yao2014}.

Utilising a simulator to aid in the training of robots is not a new concept,
but advancements in computational power and the parallel execution of
simulators has the potential to drastically reduce the time required to evolve
robotic behaviour and approximate solutions to problems encountered by robotic
agents.

